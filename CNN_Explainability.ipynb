{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdPaO9lMUa_d",
        "outputId": "9b4e5720-07c7-4d17-e034-6074a49890a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision matplotlib requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import requests\n",
        "import json"
      ],
      "metadata": {
        "id": "rD1aFhyjVNCz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "transforms.Normalize((0.5,), (0.5,))])\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
        "shuffle=True)\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
        "shuffle=False)"
      ],
      "metadata": {
        "id": "45wgEe7oVUX8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = CNN()"
      ],
      "metadata": {
        "id": "3DRg86HEVcZ_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1,\n",
        "padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1,\n",
        "padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "model = CNN()"
      ],
      "metadata": {
        "id": "N02KyklzbECY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "dq8BqBG_VhUF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(3):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in trainloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7dLcHrPWav4",
        "outputId": "2f495b8c-dba2-4201-cc0d-81ac278cfd60"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.15624879148062953\n",
            "Epoch 2, Loss: 0.044750233883532615\n",
            "Epoch 3, Loss: 0.031894040486998364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a_yeg60Xk76",
        "outputId": "18b8c9c4-796f-4682-c2ba-8b8d031060b2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 99.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "index = random.randint(0, len(images) - 1)\n",
        "img = images[index].squeeze()\n",
        "true_label = labels[index].item()\n",
        "output = model(images[index].unsqueeze(0))\n",
        "predicted_label = torch.argmax(output).item()\n",
        "plt.imshow(img.numpy(), cmap='gray')\n",
        "plt.title(f\"Predicted: {predicted_label}, True: {true_label}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "wQfiLl16daPo",
        "outputId": "a0c88caf-3b6e-40f1-bd8a-c8308217c42d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "GEMINI_API_KEY = \"AIzaSyD3XdhyLphN9lDx-i1tfGcb_Hv1s8HLV0c\"\n",
        "\n",
        "GEMINI_ENDPOINT = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent\"\n",
        "\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "prompt = \"Explain how a Convolutional Neural Network (CNN) works.\"\n",
        "\n",
        "data = {\n",
        "    \"contents\": [{\n",
        "        \"parts\": [{\"text\": prompt}]\n",
        "    }]\n",
        "}\n",
        "\n",
        "response = requests.post(f\"{GEMINI_ENDPOINT}?key={GEMINI_API_KEY}\", headers=headers, json=data)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    explanation = response.json()\n",
        "    print(\"Gemini Explanation:\", explanation)\n",
        "else:\n",
        "    print(\"Error:\", response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6097JiRchqSl",
        "outputId": "6d0cd549-d336-404e-9fbf-c09113d0d55e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Explanation: {'candidates': [{'content': {'parts': [{'text': \"A Convolutional Neural Network (CNN) is a type of artificial neural network designed specifically to process data with a grid-like topology, such as images.  Unlike a standard neural network which processes data as a flat vector, a CNN leverages the spatial relationships between data points.  Here's a breakdown of its operation:\\n\\n**1. Input Layer:** The input is typically a multi-dimensional array representing an image (e.g., a 3D array for color images with height, width, and color channels).\\n\\n**2. Convolutional Layers:** This is the core of a CNN.  These layers employ filters (also called kernels) which are small matrices of weights.  The filter slides across the input image, performing an element-wise multiplication with the underlying section of the image and summing the results. This process is called convolution.\\n\\n* **Feature Extraction:**  Each filter learns to detect a specific feature in the input.  For example, one filter might detect edges, another might detect corners, and another might detect textures. The result of the convolution is a feature map, which highlights the presence and location of that specific feature in the input image.\\n\\n* **Multiple Filters:**  A convolutional layer typically uses multiple filters, each detecting a different feature.  This allows the network to learn a rich representation of the input.\\n\\n* **Stride and Padding:**  The stride determines how many pixels the filter moves at each step.  A larger stride reduces the size of the output feature map. Padding adds extra pixels around the borders of the input image to control the output size.\\n\\n**3. Pooling Layers:**  Pooling layers reduce the dimensionality of the feature maps produced by convolutional layers. This helps to:\\n\\n* **Reduce Computational Cost:**  Smaller feature maps mean less computation in subsequent layers.\\n* **Introduce Translation Invariance:**  Pooling makes the network less sensitive to the exact location of features in the input image.  A slight shift in the feature's position won't significantly affect the output.\\n* **Reduce Overfitting:** By reducing the number of parameters, pooling helps to prevent overfitting, especially with limited training data.\\n\\nCommon pooling operations include max pooling (taking the maximum value in a region) and average pooling (taking the average value in a region).\\n\\n**4. Flattening Layer:** After several convolutional and pooling layers, the multi-dimensional feature maps are flattened into a single long vector. This vector then serves as input to the fully connected layers.\\n\\n**5. Fully Connected Layers:**  These layers are similar to those in standard neural networks.  Each neuron is connected to every neuron in the preceding layer.  These layers learn high-level representations of the features extracted by the convolutional layers and ultimately perform classification or regression.\\n\\n**6. Output Layer:**  The final layer produces the output of the network.  For classification tasks, this might be a probability distribution over different classes.  For regression tasks, it might be a continuous value.\\n\\n**In Summary:**\\n\\nA CNN works by progressively extracting increasingly complex features from the input data.  Convolutional and pooling layers learn local patterns, while fully connected layers integrate these patterns to make global decisions. The hierarchical nature of the architecture allows CNNs to effectively learn from complex visual data.  The weights of the filters and neurons are learned during the training process using backpropagation and optimization algorithms like gradient descent.\\n\"}], 'role': 'model'}, 'finishReason': 'STOP', 'avgLogprobs': -0.2244190139110906}], 'usageMetadata': {'promptTokenCount': 12, 'candidatesTokenCount': 694, 'totalTokenCount': 706, 'promptTokensDetails': [{'modality': 'TEXT', 'tokenCount': 12}], 'candidatesTokensDetails': [{'modality': 'TEXT', 'tokenCount': 694}]}, 'modelVersion': 'gemini-1.5-flash'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discuss Explainability\n",
        "    o Compare explanations for correct vs. incorrect predictions.\n",
        "While inaccurate forecasts frequently draw attention to model biases or confusion, accurate predictions have explanations that match image attributes.\n",
        "    o Discuss how LLMs enhance model interpretability.\n",
        "AI behavior becomes more comprehensible thanks to LLMs like Gemini, which offer natural language knowledge of model judgments.\n",
        "    o Highlight the importance of explainability in AI applications.\n",
        "Explainability guarantees responsible AI use in crucial areas like healthcare and finance, fosters confidence, facilitates debugging, and lessens bias."
      ],
      "metadata": {
        "id": "rqy1xehRkhd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "class CIFARCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CIFARCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(32 * 8 * 8, 64)\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 32 * 8 * 8)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model_cifar = CIFARCNN()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YLpOwV-lGuh",
        "outputId": "3ac1f8e0-9ce0-4777-fbb6-aa5a2dc75921"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: ./data/cifar-10-python.tar.gz\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_cifar.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(2):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in trainloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_cifar(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}\")\n",
        "\n",
        "print(\"Training Complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zYp2Ypp3HjH",
        "outputId": "5cfc9e53-3c29-48bb-cc5e-c8c29ebe4d30"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.4423593006018178\n",
            "Epoch 2, Loss: 1.1310281361765264\n",
            "Training Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        outputs = model_cifar(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"CIFAR-10 Test Accuracy: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9otdLIX3n8p",
        "outputId": "13b06776-f92f-4eaa-fe10-23819e3a7fc1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CIFAR-10 Test Accuracy: 61.72%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare MNIST vs. CIFAR-10 Model Complexity\n",
        "\n",
        "*   Because it can handle grayscale (1-channel) photographs of digits written by hand (28x28), the MNIST model is less complicated and requires fewer layers and parameters. Deeper networks are needed to capture complicated patterns in the CIFAR-10 model as it analyzes color (3-transmit) images of objects (32x32). Therefore, in order to improve accuracy, CIFAR-10 requires larger datasets, advanced architectures, and greater computational resources.\n"
      ],
      "metadata": {
        "id": "Nmk4zvWz4yHV"
      }
    }
  ]
}